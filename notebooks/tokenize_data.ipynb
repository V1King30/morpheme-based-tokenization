{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.normalizers import Lowercase, NFD, StripAccents, Sequence\n",
    "from tokenizers.pre_tokenizers import BertPreTokenizer\n",
    "from itertools import islice\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T12:20:20.680419Z",
     "iopub.status.busy": "2025-04-27T12:20:20.680134Z",
     "iopub.status.idle": "2025-04-27T12:20:20.684613Z",
     "shell.execute_reply": "2025-04-27T12:20:20.683501Z",
     "shell.execute_reply.started": "2025-04-27T12:20:20.680398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_list = [\n",
    "    \"/kaggle/input/ubettextfiles/ubertext_court.txt\",\n",
    "   \"/kaggle/input/ubettextfiles/ubertext_fiction.txt\",\n",
    "   \"/kaggle/input/ubettextfiles/ubertext_social.txt\",\n",
    "   \"/kaggle/input/ubettextfiles/ubertext_wikipedia.txt\",\n",
    "   \"/kaggle/input/ubettextfiles/ubertext_news.txt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T12:20:20.868200Z",
     "iopub.status.busy": "2025-04-27T12:20:20.867919Z",
     "iopub.status.idle": "2025-04-27T12:20:20.872689Z",
     "shell.execute_reply": "2025-04-27T12:20:20.871904Z",
     "shell.execute_reply.started": "2025-04-27T12:20:20.868180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MERGES_PATH = f\"/kaggle/input/morphemetokenizers/bpe_{tokenizer_size}k_full/merges.txt\"\n",
    "VOCAB_PATH = f\"/kaggle/input/morphemetokenizers/bpe_{tokenizer_size}k_full/vocab.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T14:40:06.680644Z",
     "iopub.status.busy": "2025-04-27T14:40:06.680338Z",
     "iopub.status.idle": "2025-04-27T14:40:06.684951Z",
     "shell.execute_reply": "2025-04-27T14:40:06.684242Z",
     "shell.execute_reply.started": "2025-04-27T14:40:06.680613Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = cpu_count()\n",
    "RE_PATTERN = re.compile(r\"[^а-яА-ЯіІїЇєЄґҐ0-9\\s.,!?\\\"'()-]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T14:50:02.001296Z",
     "iopub.status.busy": "2025-04-27T14:50:02.000456Z",
     "iopub.status.idle": "2025-04-27T14:50:02.010004Z",
     "shell.execute_reply": "2025-04-27T14:50:02.009253Z",
     "shell.execute_reply.started": "2025-04-27T14:50:02.001268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def batch_line_generator(file, batch_size):\n",
    "    while True:\n",
    "        lines = [clean_line(line) for line in islice(file, batch_size)]\n",
    "        lines = [line for line in lines if line]\n",
    "        if not lines:\n",
    "            break\n",
    "        yield lines\n",
    "\n",
    "def clean_line(line):\n",
    "    line = line.strip()\n",
    "    cleaned = RE_PATTERN.sub(\"\", line)\n",
    "    return cleaned if cleaned else None\n",
    "\n",
    "def process_file(args):\n",
    "    file_path, tokenizer = args\n",
    "    token_counts = []\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f_in:\n",
    "        for batch in batch_line_generator(f_in, BATCH_SIZE):\n",
    "            encoded_batch = tokenizer(batch, add_special_tokens=False, return_length=True)\n",
    "            token_counts.extend(encoded_batch[\"length\"])  # use precomputed lengths\n",
    "\n",
    "    return token_counts\n",
    "\n",
    "\n",
    "def parallel_tokenize(file_list, tokenizer):\n",
    "    args_list = [\n",
    "        (file_path, tokenizer)\n",
    "        for file_path in file_list\n",
    "    ]\n",
    "\n",
    "    all_token_counts = []\n",
    "\n",
    "    with Pool(processes=NUM_WORKERS) as pool:\n",
    "        results = pool.map(process_file, args_list)\n",
    "        for token_counts in results:\n",
    "            all_token_counts.extend(token_counts)  # flatten\n",
    "\n",
    "    return all_token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T15:12:59.672233Z",
     "iopub.status.busy": "2025-04-27T15:12:59.671921Z",
     "iopub.status.idle": "2025-04-27T15:13:03.051012Z",
     "shell.execute_reply": "2025-04-27T15:13:03.050395Z",
     "shell.execute_reply.started": "2025-04-27T15:12:59.672210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "login(token=\"hf_token\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"m/gemma-7b\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T12:20:24.192620Z",
     "iopub.status.busy": "2025-04-27T12:20:24.191796Z",
     "iopub.status.idle": "2025-04-27T12:20:24.219453Z",
     "shell.execute_reply": "2025-04-27T12:20:24.218127Z",
     "shell.execute_reply.started": "2025-04-27T12:20:24.192594Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/3915777416.py:1: DeprecationWarning: Deprecated in 0.9.0: BPE.__init__ will not create from files anymore, try `BPE.from_file` instead\n",
      "  bpe_model = BPE(\n"
     ]
    }
   ],
   "source": [
    "bpe_model = BPE(\n",
    "        vocab=VOCAB_PATH,\n",
    "        merges=MERGES_PATH,\n",
    "        unk_token=\"[UNK]\"\n",
    "    )\n",
    "tokenizer = Tokenizer(bpe_model)\n",
    "tokenizer.normalizer = Sequence([NFD(), Lowercase()])\n",
    "tokenizer.pre_tokenizer = BertPreTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T15:13:09.480706Z",
     "iopub.status.busy": "2025-04-27T15:13:09.480185Z",
     "iopub.status.idle": "2025-04-27T15:30:36.023234Z",
     "shell.execute_reply": "2025-04-27T15:30:36.022392Z",
     "shell.execute_reply.started": "2025-04-27T15:13:09.480680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 16930386\n",
      "Avg tokens/line: 30.51459252021779\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # mp.set_start_method(\"forkserver\")\n",
    "\n",
    "    token_counts = parallel_tokenize(\n",
    "        train_text_list,\n",
    "        tokenizer\n",
    "    )\n",
    "\n",
    "    print(\"Lines:\", len(token_counts))\n",
    "    print(\"Avg tokens/line:\", sum(token_counts) / len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T15:37:31.521654Z",
     "iopub.status.busy": "2025-04-27T15:37:31.521314Z",
     "iopub.status.idle": "2025-04-27T15:37:31.621993Z",
     "shell.execute_reply": "2025-04-27T15:37:31.621297Z",
     "shell.execute_reply.started": "2025-04-27T15:37:31.521625Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516623830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T12:39:48.005691Z",
     "iopub.status.busy": "2025-04-27T12:39:48.005091Z",
     "iopub.status.idle": "2025-04-27T12:39:48.022655Z",
     "shell.execute_reply": "2025-04-27T12:39:48.021891Z",
     "shell.execute_reply.started": "2025-04-27T12:39:48.005659Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16930386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T12:39:48.024482Z",
     "iopub.status.busy": "2025-04-27T12:39:48.024227Z",
     "iopub.status.idle": "2025-04-27T12:39:54.002353Z",
     "shell.execute_reply": "2025-04-27T12:39:54.001414Z",
     "shell.execute_reply.started": "2025-04-27T12:39:48.024464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f'/kaggle/working/tokenized_{tokenizer_size}k.json', 'w') as f:\n",
    "    json.dump({'token_counts': token_counts}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62e30423145a93faf211ab9b704908ae7403ade2b25694c7d14278daea2f18c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
