{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T06:12:26.492314Z","iopub.status.busy":"2025-04-23T06:12:26.491981Z","iopub.status.idle":"2025-04-23T06:12:31.857361Z","shell.execute_reply":"2025-04-23T06:12:31.856238Z","shell.execute_reply.started":"2025-04-23T06:12:26.492283Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tokenizers==0.21.0 in /usr/local/lib/python3.11/dist-packages (0.21.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers==0.21.0) (0.30.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (4.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2025.1.31)\n"]}],"source":["!pip install tokenizers==0.21.0"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T06:12:31.860992Z","iopub.status.busy":"2025-04-23T06:12:31.860569Z","iopub.status.idle":"2025-04-23T06:12:31.940866Z","shell.execute_reply":"2025-04-23T06:12:31.939960Z","shell.execute_reply.started":"2025-04-23T06:12:31.860952Z"},"trusted":true},"outputs":[],"source":["from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.pre_tokenizers import Whitespace, Punctuation\n","from tokenizers.normalizers import Lowercase, NFD, StripAccents, Sequence\n","from tokenizers.processors import BertProcessing\n","from tokenizers.pre_tokenizers import PreTokenizer\n","from tokenizers.implementations import ByteLevelBPETokenizer\n","from itertools import islice\n","from tokenizers.pre_tokenizers import BertPreTokenizer\n","\n","import os\n","import re"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T06:12:31.942046Z","iopub.status.busy":"2025-04-23T06:12:31.941742Z","iopub.status.idle":"2025-04-23T06:12:31.947481Z","shell.execute_reply":"2025-04-23T06:12:31.946271Z","shell.execute_reply.started":"2025-04-23T06:12:31.942018Z"},"trusted":true},"outputs":[],"source":["# === Step 1: Prepare morphemes ===\n","special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T06:12:31.948981Z","iopub.status.busy":"2025-04-23T06:12:31.948651Z","iopub.status.idle":"2025-04-23T06:12:31.966773Z","shell.execute_reply":"2025-04-23T06:12:31.965867Z","shell.execute_reply.started":"2025-04-23T06:12:31.948952Z"},"trusted":true},"outputs":[],"source":["# === Step 2: Prepare training data ===\n","def batch_line_iterator(file_list, batch_size=32):\n","    def line_iterator():\n","        for file in file_list:\n","            with open(file, mode=\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n","                for line in f:\n","                    line = line.strip()\n","                    if line:\n","                        yield re.sub(r\"[^а-яА-ЯіІїЇєЄґҐa-zA-Z0-9\\s.,!?\\\"'()-]\", \"\", line)\n","\n","    iterator = line_iterator()\n","    while True:\n","        batch = list(islice(iterator, batch_size))\n","        if not batch:\n","            break\n","        yield batch"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T06:12:31.969512Z","iopub.status.busy":"2025-04-23T06:12:31.969248Z","iopub.status.idle":"2025-04-23T06:12:32.006868Z","shell.execute_reply":"2025-04-23T06:12:32.005710Z","shell.execute_reply.started":"2025-04-23T06:12:31.969492Z"},"trusted":true},"outputs":[],"source":["# === Step 3: Initialize Tokenizer ===\n","tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n","\n","alphabet = list(\"абвгґдеєжзиіїйклмнопрстуфхцчшщьюяabcdefghijklmnopqrstuvwxyz0123456789.,!?\\\"' \")\n","\n","# Optional: normalize + pre-tokenize\n","tokenizer.normalizer = Sequence([NFD(), Lowercase()])\n","tokenizer.pre_tokenizer = BertPreTokenizer()\n","\n","# === Step 4: Train BPE with morphemes as initial alphabet ===\n","trainer = BpeTrainer(\n","    vocab_size=3000,\n","    show_progress=True,\n","    initial_alphabet=alphabet,\n","    special_tokens=special_tokens,\n","    max_token_length=9\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T06:12:32.008212Z","iopub.status.busy":"2025-04-23T06:12:32.007891Z","iopub.status.idle":"2025-04-23T07:01:32.020704Z","shell.execute_reply":"2025-04-23T07:01:32.019365Z","shell.execute_reply.started":"2025-04-23T06:12:32.008185Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\n"]}],"source":["train_text_list = [\"/kaggle/input/ubettextfiles/ubertext_court.txt\",\n","                       \"/kaggle/input/ubettextfiles/ubertext_fiction.txt\",\n","                       \"/kaggle/input/ubettextfiles/ubertext_social.txt\",\n","                       \"/kaggle/input/ubettextfiles/ubertext_wikipedia.txt\"\n","                       ]\n","\n","tokenizer.train_from_iterator(batch_line_iterator(train_text_list, batch_size=512), trainer)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T07:01:32.024490Z","iopub.status.busy":"2025-04-23T07:01:32.024091Z","iopub.status.idle":"2025-04-23T07:01:32.034413Z","shell.execute_reply":"2025-04-23T07:01:32.033585Z","shell.execute_reply.started":"2025-04-23T07:01:32.024464Z"},"trusted":true},"outputs":[],"source":["vocab = tokenizer.get_vocab()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T07:01:32.096238Z","iopub.status.busy":"2025-04-23T07:01:32.095987Z","iopub.status.idle":"2025-04-23T07:01:32.106951Z","shell.execute_reply":"2025-04-23T07:01:32.106161Z","shell.execute_reply.started":"2025-04-23T07:01:32.096212Z"},"trusted":true},"outputs":[{"data":{"text/plain":["3000"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["len(vocab)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T07:01:32.057793Z","iopub.status.busy":"2025-04-23T07:01:32.057553Z","iopub.status.idle":"2025-04-23T07:01:32.090695Z","shell.execute_reply":"2025-04-23T07:01:32.089654Z","shell.execute_reply.started":"2025-04-23T07:01:32.057775Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['morpheme_bpe_3k_tokenizer/vocab.json',\n"," 'morpheme_bpe_3k_tokenizer/merges.txt']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# === Step 5: Save tokenizer ===\n","os.makedirs(\"morpheme_bpe_3k_tokenizer\", exist_ok=True)\n","tokenizer.model.save(\"morpheme_bpe_3k_tokenizer\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2025-04-23T07:15:46.040884Z","iopub.status.busy":"2025-04-23T07:15:46.038794Z","iopub.status.idle":"2025-04-23T07:15:46.055804Z","shell.execute_reply":"2025-04-23T07:15:46.054520Z","shell.execute_reply.started":"2025-04-23T07:15:46.040827Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokens: ['про', 'чита', 'ти', 'вироб', 'ництво']\n"]}],"source":["# === Optional: Test it ===\n","tokenizer.enable_padding(pad_id=0, pad_token=\"[PAD]\")\n","output = tokenizer.encode(\"прочитати виробництво\")\n","print(\"Tokens:\", output.tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":7217600,"sourceId":11510467,"sourceType":"datasetVersion"}],"dockerImageVersionId":31012,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"62e30423145a93faf211ab9b704908ae7403ade2b25694c7d14278daea2f18c6"}}},"nbformat":4,"nbformat_minor":4}
